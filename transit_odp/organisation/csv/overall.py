from collections import OrderedDict

import pandas as pd
from pandas import DataFrame, merge
from waffle import flag_is_active

from transit_odp.common.collections import Column
from transit_odp.fares.models import DataCatalogueMetaData
from transit_odp.organisation.csv import EmptyDataFrame
from transit_odp.organisation.models import Dataset, TXCFileAttributes

FEATURE_FLAG_OVERALL_COLUMN_MAP = OrderedDict(
    {
        "organisation_name": Column(
            "Operator", "The name of the operator/publisher providing data on BODS."
        ),
        "organisation_id": Column(
            "Operator ID",
            "The internal BODS generated ID of the operator/publisher providing"
            " data on BODS.",
        ),
        "profile_nocs": Column(
            "Profile NOCs",
            (
                "The National Operator Codes for the particular publisher as extracted "
                "from their BODS profile."
            ),
        ),
        "dataset_type_pretty": Column("Data Type", "The type of data being published."),
        "status": Column("Status", "The publication status of the data set/feed."),
        "last_updated": Column(
            "Last Updated", "The date that the data set/feed was last updated on BODS."
        ),
        "upload_filename": Column(
            "File Name",
            "The exact name of the file provided to BODS. This is usually generated by "
            "the publisher or their supplier",
        ),
        "filename": Column(
            "XML File Name",
            "The value of the FileName attribute in the TransXChange or NeTEx file.",
        ),
        "name": Column(
            "Data Set/Feed Name",
            "The internal BODS generated data set name given for a particular"
            " data set.",
        ),
        "id": Column(
            "Data ID",
            "The internal BODS generated ID of the data set / feed provided to BODS.",
        ),
        "mode": Column(
            "Mode",
            "The mode of transport as extracted from the TransXChange "
            "file they provided.",
        ),
        "national_operator_code": Column(
            "National Operator Code",
            "The National Operator Codes for the particular publisher as extracted "
            "from the TransXChange or NeTEx file they provided.",
        ),
        "service_code": Column(
            "Service Code",
            "The ServiceCode for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
        "string_lines": Column(
            "Line Name",
            "The linename for the particular publisher as extracted from "
            "the TransXChange or NeTEx file they provided.",
        ),
    }
)

OVERALL_COLUMN_MAP = OrderedDict(
    {
        "organisation_name": Column(
            "Operator", "The name of the operator/publisher providing data on BODS."
        ),
        "organisation_id": Column(
            "Operator ID",
            "The internal BODS generated ID of the operator/publisher providing"
            " data on BODS.",
        ),
        "profile_nocs": Column(
            "Profile NOCs",
            (
                "The National Operator Codes for the particular publisher as extracted "
                "from their BODS profile."
            ),
        ),
        "dataset_type_pretty": Column("Data Type", "The type of data being published."),
        "status": Column("Status", "The publication status of the data set/feed."),
        "last_updated": Column(
            "Last Updated", "The date that the data set/feed was last updated on BODS."
        ),
        "upload_filename": Column(
            "File Name",
            "The exact name of the file provided to BODS. This is usually generated by "
            "the publisher or their supplier",
        ),
        "filename": Column(
            "TXC File Name",
            "The value of the FileName attribute in the TransXChange file.",
        ),
        "name": Column(
            "Data Set/Feed Name",
            "The internal BODS generated data set name given for a particular"
            " data set.",
        ),
        "id": Column(
            "Data ID",
            "The internal BODS generated ID of the data set / feed provided to BODS.",
        ),
        "mode": Column(
            "Mode",
            "The mode of transport as extracted from the TransXChange "
            "file they provided.",
        ),
        "national_operator_code": Column(
            "National Operator Code",
            "The National Operator Codes for the particular publisher as extracted"
            " from the TransXChange file they provided.",
        ),
        "service_code": Column(
            "Service Code",
            "The ServiceCode for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
        "string_lines": Column(
            "Line Name",
            "The linename for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
    }
)

DATASET_FIELDS = (
    "organisation_name",
    "organisation_id",
    "profile_nocs",
    "dataset_type_pretty",
    "status",
    "last_updated",
    "upload_filename",
    "id",
    "name",
)

TXC_FILE_ATTRIBUTE_FIELDS = (
    "dataset_id",
    "filename",
    "national_operator_code",
    "service_code",
    "string_lines",
)

DATACATALOGUE_ATTRIBUTE_FIELDS = (
    "dataset_id",
    "fares_metadata_id",
    "xml_file_name",
    "string_nocs",
    "string_lines",
)


def _get_overall_catalogue_dataframe() -> DataFrame:
    is_fares_validator_active = flag_is_active("", "is_fares_validator_active")
    dataset_df = DataFrame.from_records(
        Dataset.objects.get_overall_data_catalogue_annotations().values(*DATASET_FIELDS)
    )

    txc_file_attributes_df = DataFrame.from_records(
        TXCFileAttributes.objects.get_overall_data_catalogue().values(
            *TXC_FILE_ATTRIBUTE_FIELDS
        )
    )

    if dataset_df.empty or txc_file_attributes_df.empty:
        raise EmptyDataFrame()

    if is_fares_validator_active:
        dataset_df_fares = dataset_df[dataset_df["dataset_type_pretty"] == "Fares"]
        dataset_df = dataset_df[dataset_df["dataset_type_pretty"] != "Fares"]

        if dataset_df_fares.empty and dataset_df.empty:
            raise EmptyDataFrame()

        datacatalogue_metadata_df = DataFrame.from_records(
            DataCatalogueMetaData.objects.get_fares_overall_catalogue().values(
                *DATACATALOGUE_ATTRIBUTE_FIELDS
            )
        )
        if datacatalogue_metadata_df.empty:
            raise EmptyDataFrame()

        datacatalogue_metadata_df.rename(
            columns={"string_nocs": "national_operator_code"}, inplace=True
        )
        datacatalogue_metadata_df.rename(
            columns={"xml_file_name": "filename"}, inplace=True
        )

        merged_fares = merge(
            dataset_df_fares,
            datacatalogue_metadata_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )
        merged_txc = merge(
            dataset_df,
            txc_file_attributes_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )
        merged = pd.concat([merged_fares, merged_txc], ignore_index=True)
    else:
        merged = merge(
            dataset_df,
            txc_file_attributes_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )

    merged["mode"] = "Bus"
    merged = merged.sort_values("id")

    if is_fares_validator_active:
        rename_map = {
            old_name: column_tuple.field_name
            for old_name, column_tuple in FEATURE_FLAG_OVERALL_COLUMN_MAP.items()
        }
        merged = merged[FEATURE_FLAG_OVERALL_COLUMN_MAP.keys()].rename(
            columns=rename_map
        )
    else:
        rename_map = {
            old_name: column_tuple.field_name
            for old_name, column_tuple in OVERALL_COLUMN_MAP.items()
        }
        merged = merged[OVERALL_COLUMN_MAP.keys()].rename(columns=rename_map)

    return merged


def get_overall_data_catalogue_csv() -> str:
    return _get_overall_catalogue_dataframe().to_csv(index=False)
